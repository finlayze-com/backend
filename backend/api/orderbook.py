# backend/api/orderbook.py
# -*- coding: utf-8 -*-

from enum import Enum
from collections import defaultdict
from fastapi import APIRouter, Query, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
import pandas as pd
from datetime import datetime, time
from zoneinfo import ZoneInfo
import re  # ğŸ‘ˆ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø³Ù…ÛŒâ€ŒÚ©Ø§Ù„Ù† Ø§Ù†ØªÙ‡Ø§ÛŒÛŒ SQL

from backend.api.metadata import get_db
from backend.users.dependencies import require_permissions
from backend.utils.sql_loader import load_sql
from backend.utils.response import create_response


router = APIRouter(prefix="/orderbook", tags=["ğŸ“Š Orderbook"])


class Mode(str, Enum):
    sector = "sector"
    intra = "intra-sector"


def normalize_persian(text_val: str | None):
    """
    Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø­Ø±ÙˆÙ Ø¹Ø±Ø¨ÛŒ/ÙØ§Ø±Ø³ÛŒ + Ø­Ø°Ù Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡ Ùˆ Ú©Ø´ÛŒØ¯Ú¯ÛŒ
    ØªØ§ Ù…Ø´Ú©Ù„ Â«Ù‡Ø§ÙŠ/Ù‡Ø§ÛŒÂ» Ùˆ Â«Ùƒ/Ú©Â» Ø¯Ø± Ù†Ø§Ù… ØµÙ†Ø¹Øª Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ….
    """
    if text_val is None:
        return None
    if not isinstance(text_val, str):
        text_val = str(text_val)

    text_val = text_val.strip().lower()
    replacements = [
        ("ÙŠ", "ÛŒ"),        # ya Ø¹Ø±Ø¨ÛŒ â†’ ya ÙØ§Ø±Ø³ÛŒ
        ("Ùƒ", "Ú©"),        # kaf Ø¹Ø±Ø¨ÛŒ â†’ kaf ÙØ§Ø±Ø³ÛŒ
        ("\u200c", ""),    # Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡ (ZWNJ)
        ("Ù€", ""),         # Ú©Ø´ÛŒØ¯Ú¯ÛŒ
    ]
    for src, dst in replacements:
        text_val = text_val.replace(src, dst)
    return text_val


@router.get("/bumpchart", summary="Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø®Ø§Ù„Øµ Ø³ÙØ§Ø±Ø´â€ŒÙ‡Ø§ (Bump Chart)")
async def get_orderbook_bumpchart_data(
    mode: Mode = Query(Mode.sector, description="sector ÛŒØ§ intra-sector"),
    sector: str | None = Query(None, description="Ù†Ø§Ù… ØµÙ†Ø¹Øª Ø¯Ø± Ø­Ø§Ù„Øª intra-sector"),
    db: AsyncSession = Depends(get_db),
    _=Depends(require_permissions("Report.OrderBook.BumpChart", "ALL")),
):
    # 1) Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    if mode == Mode.intra and not sector:
        raise HTTPException(status_code=400, detail="sector is required in intra-sector mode")

    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… ØµÙ†Ø¹Øª (Ù…Ø«Ù„ treemap & sankey)
    norm_sector = normalize_persian(sector) if sector else None

    # 2) SQL Ù¾Ø§ÛŒÙ‡ + Ø­Ø°Ù Ø³Ù…ÛŒâ€ŒÚ©Ø§Ù„Ù† Ø§Ù†ØªÙ‡Ø§ÛŒÛŒ
    base_sql = load_sql("orderbook_sector_timeseries") if mode == Mode.sector else load_sql("orderbook_intrasector_timeseries")
    base_sql_clean = re.sub(r";\s*$", "", base_sql.strip())  # ğŸ‘ˆ Ø³Ù…ÛŒâ€ŒÚ©Ø§Ù„Ù† Ù¾Ø§ÛŒØ§Ù†ÛŒ Ø±Ø§ Ø¨Ø±Ø¯Ø§Ø±

    group_col = "sector" if mode == Mode.sector else "Symbol"

    # 3) Ø¨Ø§Ø²Ù‡ Ø§Ù…Ø±ÙˆØ² ØªÙ‡Ø±Ø§Ù† 09:00â€“13:00 (Ø³ØªÙˆÙ† minute tz-naive Ø§Ø³Øª â†’ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ù‡Ù… tz-naive)
    now_teh = datetime.now(ZoneInfo("Asia/Tehran"))
    today_teh = now_teh.date()
    start_teh_aware = datetime.combine(today_teh, time(9, 0), tzinfo=ZoneInfo("Asia/Tehran"))
    end_teh_aware = datetime.combine(today_teh, time(13, 0), tzinfo=ZoneInfo("Asia/Tehran"))
    start_naive = start_teh_aware.replace(tzinfo=None)
    end_naive = end_teh_aware.replace(tzinfo=None)

    # 4) Wrap Ø¨Ù‡â€ŒØµÙˆØ±Øª CTE + ÙÛŒÙ„ØªØ± Ø¨Ø§Ø²Ù‡ Ø¯Ø± SQL
    sql = f"""
    WITH src AS (
        {base_sql_clean}
    )
    SELECT *
    FROM src
    WHERE minute >= :start AND minute < :end
    """

    params: dict = {"start": start_naive, "end": end_naive}
    if mode == Mode.intra:
        # Ø§ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¨Ù‡ orderbook_intrasector_timeseries Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        # Ø§Ú¯Ø± Ø¢Ù† SQL Ø±Ø§ Ù…Ø«Ù„ sankey Ø¨Ù‡ REPLACE/REPLACE Ù…Ø¬Ù‡Ø² Ú©Ù†ÛŒØŒ
        # Ø¨Ù‡ØªØ± Ø§Ø³Øª Ù‡Ù…ÛŒÙ† norm_sector Ø±Ø§ Ø¨ÙØ±Ø³ØªÛŒ
        params["sector"] = norm_sector or sector

    # 5) Ø§Ø¬Ø±Ø§
    res = await db.execute(text(sql), params)
    rows = res.mappings().all()
    if not rows:
        return create_response(
            data=[],
            message="âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø§Ù…Ø±ÙˆØ² (09:00 ØªØ§ 13:00) ÛŒØ§ÙØª Ù†Ø´Ø¯",
            status_code=200,
        )

    df = pd.DataFrame(rows)

    # Ø§Ú¯Ø± Ø³ØªÙˆÙ† sector ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ù…Ø«Ù„ Ø¨Ù‚ÛŒÙ‡ Ø±ÙˆØªâ€ŒÙ‡Ø§ Ù†Ø±Ù…Ø§Ù„Ø´ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    if "sector" in df.columns:
        df["sector_norm"] = df["sector"].astype(str).apply(normalize_persian)
        # Ø§Ú¯Ø± mode=intra Ùˆ sector Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ØŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø±ÙˆÛŒ df ÙÛŒÙ„ØªØ± Ù†Ø±Ù… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        if mode == Mode.intra and norm_sector:
            df = df[df["sector_norm"] == norm_sector]
            if df.empty:
                return create_response(
                    data=[],
                    message=f"Ø¨Ø±Ø§ÛŒ Ø³Ú©ØªÙˆØ± Â«{sector}Â» (Ø¨Ø¹Ø¯ Ø§Ø² Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ) Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
                    status_code=200,
                )

    # 6) Ú†Ú© Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
    need = {"total_buy", "total_sell", "minute", group_col}
    miss = need - set(df.columns)
    if miss:
        raise HTTPException(status_code=500, detail=f"Missing columns: {', '.join(miss)}")

    # 7) Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ø§Øª
    df["net_value"] = (df["total_buy"].fillna(0) - df["total_sell"].fillna(0)).astype(float)
    df["minute"] = pd.to_datetime(df["minute"], errors="coerce")
    df = df.dropna(subset=["minute"]).sort_values("minute")

    minutes = sorted(df["minute"].unique())
    if not minutes:
        return create_response(data=[], message="Ù‡ÛŒÚ† Ø²Ù…Ø§Ù† Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯", status_code=200)

    groups = df[group_col].astype(str).unique().tolist()

    tmp = df.groupby(["minute", group_col], as_index=False)["net_value"].sum()

    bump = defaultdict(list)
    for m in minutes:
        sm = tmp[tmp["minute"] == pd.Timestamp(m)]
        if sm.empty:
            for g in groups:
                bump[g].append(None)
            continue
        sm = sm.sort_values("net_value", ascending=False).reset_index(drop=True)
        sm["rank"] = sm.index + 1
        rank_map = dict(zip(sm[group_col].astype(str), sm["rank"]))
        for g in groups:
            bump[g].append(int(rank_map[g]) if g in rank_map else None)

    ranking_df = pd.DataFrame(bump, index=minutes).ffill().bfill()

    payload = {
        "minutes": [pd.Timestamp(m).strftime("%H:%M") for m in minutes],
        "series": [{"name": g, "ranks": ranking_df[g].tolist()} for g in groups],
    }
    return create_response(
        data=payload,
        message="âœ… Bump chart ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ù…Ø±ÙˆØ² (09:00 ØªØ§ 13:00)",
        status_code=200,
    )
