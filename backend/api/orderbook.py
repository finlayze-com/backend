# backend/api/orderbook.py
from enum import Enum
from collections import defaultdict
from fastapi import APIRouter, Query, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
import pandas as pd

from backend.api.metadata import get_db
from backend.users.dependencies import require_permissions
from backend.utils.sql_loader import load_sql
from backend.utils.response import create_response  # Ù¾Ø§Ø³Ø® ÙˆØ§Ø­Ø¯

router = APIRouter(prefix="/orderbook", tags=["ðŸ“Š Orderbook"])

class Mode(str, Enum):
    sector = "sector"
    intra = "intra-sector"

@router.get("/bumpchart", summary="Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø®Ø§Ù„Øµ Ø³ÙØ§Ø±Ø´â€ŒÙ‡Ø§ (Bump Chart)")
async def get_orderbook_bumpchart_data(
    mode: Mode = Query(Mode.sector, description="sector ÛŒØ§ intra-sector"),
    sector: str | None = Query(None, description="Ù†Ø§Ù… ØµÙ†Ø¹Øª Ø¯Ø± Ø­Ø§Ù„Øª intra-sector"),
    db: AsyncSession = Depends(get_db),
    _=Depends(require_permissions("Report.OrderBook.BumpChart","ALL"))
):
    # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    if mode == Mode.intra and not sector:
        raise HTTPException(status_code=400, detail="sector is required in intra-sector mode")

    # Ø§Ù†ØªØ®Ø§Ø¨ SQL
    if mode == Mode.sector:
        sql = load_sql("orderbook_sector_timeseries")
        params = {}
        group_col = "sector"
    else:
        sql = load_sql("orderbook_intrasector_timeseries")
        params = {"sector": sector}
        group_col = "Symbol"

    # Ø§Ø¬Ø±Ø§ÛŒ Async
    res = await db.execute(text(sql), params)
    rows = res.mappings().all()
    if not rows:
        return create_response(data=[], message="Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯", status_code=200)

    df = pd.DataFrame(rows)

    # âœ… ÙÛŒÙ„ØªØ± ÙÙ‚Ø· Â«Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ² Ø§Ø² Ø³Ø§Ø¹Øª 08:30 Ø¨Ù‡ Ø¨Ø¹Ø¯Â»
    # - Ø§Ú¯Ø± Ø³ØªÙˆÙ† minute tz-naive Ø¨Ø§Ø´Ø¯ (timestamp without time zone) Ùˆ Ø¨Ù‡ ÙˆÙ‚Øª ØªÙ‡Ø±Ø§Ù† Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡:
    #   Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø­Ù„ÛŒ Ø¨Ù‡ Asia/Tehran Ù†Ø³Ø¨Øª Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù…Ù‚Ø¯Ø§Ø± Ø¸Ø§Ù‡Ø±ÛŒ).
    # - Ø³Ù¾Ø³ Ø¨Ø§Ø²Ù‡ Ø§Ù…Ø±ÙˆØ²Ù ØªÙ‡Ø±Ø§Ù† [08:30, 24:00) Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ….
    df["minute"] = pd.to_datetime(df["minute"], errors="coerce")
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø²Ù…Ø§Ù†Ù Ø¢Ú¯Ø§Ù‡ Ø§Ø² Ù…Ù†Ø·Ù‚Ù‡ Ø²Ù…Ø§Ù†ÛŒ ØªÙ‡Ø±Ø§Ù† (localize) - Ù…Ù‚Ø¯Ø§Ø± Ù„Ø­Ø¸Ù‡ Ø±Ø§ ØªØºÛŒÛŒØ± Ù†Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ ÙÙ‚Ø· TZ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    df["minute_local"] = df["minute"].dt.tz_localize("Asia/Tehran", nonexistent="shift_forward", ambiguous="NaT")

    tehran_now = pd.Timestamp.now(tz="Asia/Tehran")
    today_teh = tehran_now.normalize()                             # 00:00 Ø§Ù…Ø±ÙˆØ² Ø¨Ù‡ ÙˆÙ‚Øª ØªÙ‡Ø±Ø§Ù†
    start_teh = today_teh + pd.Timedelta(hours=8, minutes=30)      # 08:30 Ø§Ù…Ø±ÙˆØ²
    end_teh   = today_teh + pd.Timedelta(days=1)                   # 00:00 ÙØ±Ø¯Ø§

    # ÙÙ‚Ø· Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ø¨Ø§Ø²Ù‡â€ŒÛŒ Ø§Ù…Ø±ÙˆØ² ØªÙ‡Ø±Ø§Ù† Ùˆ Ø§Ø² 08:30 Ø¨Ù‡ Ø¨Ø¹Ø¯ Ù‡Ø³ØªÙ†Ø¯
    df = df[(df["minute_local"] >= start_teh) & (df["minute_local"] < end_teh)]

    # Ø§Ú¯Ø± Ø¨Ø¹Ø¯ Ø§Ø² ÙÛŒÙ„ØªØ± Ø§Ù…Ø±ÙˆØ² Ú†ÛŒØ²ÛŒ Ù†Ù…Ø§Ù†Ø¯ØŒ Ù¾Ø§Ø³Ø® Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø¯Ù‡
    if df.empty:
        return create_response(data=[], message="Ø¨Ø±Ø§ÛŒ Ø§Ù…Ø±ÙˆØ² Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª", status_code=200)

    # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯Ù†ÛŒØ§Ø²
    need = {"total_buy", "total_sell", "minute", group_col}
    miss = need - set(df.columns)
    if miss:
        raise HTTPException(status_code=500, detail=f"Missing columns: {', '.join(miss)}")

    # Ø®Ø§Ù„Øµ Ø³ÙØ§Ø±Ø´
    df["net_value"] = df["total_buy"] - df["total_sell"]
    df = df.fillna(0)

    # Ø³Ø§Ø®Øª Ø¯Ø§Ø¯Ù‡ Ø±ØªØ¨Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Bump Chart
    # â¬…ï¸ Ø¨Ø±Ø§ÛŒ Ù‡Ù…â€ŒØ®ÙˆØ§Ù†ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±ØŒ Ù…Ø­ÙˆØ± Ø²Ù…Ø§Ù†ÛŒ Ø±Ø§ Ø§Ø² minute_local Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ….
    minutes = sorted(df["minute_local"].unique())
    groups = df[group_col].unique().tolist()
    bump = defaultdict(list)

    for m in minutes:
        tmp = df[df["minute_local"] == m].groupby(group_col)["net_value"].sum().reset_index()
        tmp = tmp.sort_values("net_value", ascending=False).reset_index(drop=True)
        tmp["rank"] = tmp.index + 1
        rank_map = dict(zip(tmp[group_col], tmp["rank"]))
        for g in groups:
            bump[g].append(int(rank_map[g]) if g in rank_map else None)

    # ÙÙˆØ±ÙˆØ§Ø±Ø¯/Ø¨Ú©ÙˆØ§Ø±Ø¯ ÙÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù¾Ø± Ú©Ø±Ø¯Ù† None
    ranking_df = pd.DataFrame(bump, index=minutes).ffill().bfill()
    bump_filled = ranking_df.to_dict(orient="list")

    # Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
    payload = {
        # Ø§Ú¯Ø± Ø®Ø±ÙˆØ¬ÛŒ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ ÙÙ‚Ø· Ø³Ø§Ø¹Øª/Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ø¯Ù‡ÛŒ:
        # "minutes": [pd.Timestamp(m).strftime("%H:%M") for m in minutes],
        "minutes": [str(m) for m in minutes],
        "series": [{"name": g, "ranks": bump_filled[g]} for g in groups]
    }
    return create_response(data=payload, message="âœ… Bump chart generated", status_code=200)
