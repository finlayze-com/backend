# backend/api/orderbook.py
# -*- coding: utf-8 -*-

from enum import Enum
from collections import defaultdict
from fastapi import APIRouter, Query, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
import pandas as pd
from datetime import datetime, time
import re

from backend.api.metadata import get_db
from backend.users.dependencies import require_permissions
from backend.utils.sql_loader import load_sql
from backend.utils.response import create_response


router = APIRouter(prefix="/orderbook", tags=["ğŸ“Š Orderbook"])


class Mode(str, Enum):
    sector = "sector"
    intra = "intra-sector"


def normalize_persian(t: str | None):
    """Normalize Persian/Arabic characters."""
    if t is None:
        return None
    if not isinstance(t, str):
        t = str(t)
    t = t.strip().lower()
    return (
        t.replace("ÙŠ", "ÛŒ")
         .replace("Ùƒ", "Ú©")
         .replace("\u200c", "")
         .replace("Ù€", "")
    )


@router.get("/bumpchart", summary="Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø®Ø§Ù„Øµ Ø³ÙØ§Ø±Ø´â€ŒÙ‡Ø§ (Bump Chart)")
async def get_orderbook_bumpchart_data(
    mode: Mode = Query(Mode.sector),
    sector: str | None = Query(None),
    db: AsyncSession = Depends(get_db),
    _=Depends(require_permissions("Report.OrderBook.BumpChart", "ALL")),
):
    # --- Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ---
    if mode == Mode.intra and not sector:
        raise HTTPException(status_code=400, detail="sector is required in intra-sector mode")

    # Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² ÙÙ‚Ø· ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±
    norm_sector = normalize_persian(sector) if sector else None

    # --- Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø§Ø² orderbook_snapshot ---
    last_day_res = await db.execute(
        text('SELECT MAX("Timestamp"::date) AS d FROM orderbook_snapshot')
    )
    last_day = last_day_res.scalar()
    if not last_day:
        return create_response(
            data=[],
            message="âŒ Ù‡ÛŒÚ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ orderbook_snapshot ÛŒØ§ÙØª Ù†Ø´Ø¯.",
            status_code=200,
        )

    # --- Load SQL Ø¨Ø± Ø§Ø³Ø§Ø³ mode ---
    sql_name = "orderbook_sector_timeseries" if mode == Mode.sector else "orderbook_intrasector_timeseries"
    base_sql = load_sql(sql_name)
    base_sql_clean = re.sub(r";\s*$", "", base_sql.strip())

    group_col = "sector" if mode == Mode.sector else "Symbol"

    # --- Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø±ÙˆÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ (09:00 - 13:00) ---
    start_naive = datetime.combine(last_day, time(9, 0))
    end_naive   = datetime.combine(last_day, time(13, 0))

    sql = f"""
    WITH src AS (
        {base_sql_clean}
    )
    SELECT *
    FROM src
    WHERE minute >= :start AND minute < :end
    """

    params = {"start": start_naive, "end": end_naive}

    # ğŸ”¥ ÙÙ‚Ø· Ø¯Ø± Ø­Ø§Ù„Øª intra-sector Ù¾Ø§Ø±Ø§Ù…ØªØ± sector Ø¨Ù‡ SQL Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
    if mode == Mode.intra:
        params["sector"] = sector

    # --- Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ ---
    res = await db.execute(text(sql), params)
    rows = res.mappings().all()
    if not rows:
        return create_response(
            data=[],
            message="âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ (09:00 ØªØ§ 13:00) ÛŒØ§ÙØª Ù†Ø´Ø¯.",
            status_code=200,
        )

    df = pd.DataFrame(rows)

    # --- Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† sector Ø¯Ø± Ø­Ø§Ù„Øª intra ---
    if mode == Mode.intra and norm_sector:
        if "Sector" in df.columns:
            df["sector_norm"] = df["Sector"].astype(str).apply(normalize_persian)
        elif "sector" in df.columns:
            df["sector_norm"] = df["sector"].astype(str).apply(normalize_persian)
        else:
            df["sector_norm"] = None

        df = df[df["sector_norm"] == norm_sector]

        if df.empty:
            return create_response(
                data=[],
                message=f"Ø¨Ø¹Ø¯ Ø§Ø² Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Â«{sector}Â» Ø¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
                status_code=200,
            )

    # --- ğŸ” ÙÛŒÙ„ØªØ± instrument_type ÙÙ‚Ø· Ø¯Ø± Ø­Ø§Ù„Øª intrasector ---
    if mode == Mode.intra:
        allowed_types = {"saham", "retail", "block", "rights_issue"}
        if "instrument_type" in df.columns:
            df["instrument_type"] = df["instrument_type"].astype(str).str.lower()
            df = df[df["instrument_type"].isin(allowed_types)]
            if df.empty:
                return create_response(
                    data=[],
                    message="Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ÛŒ Ø¨Ø§ instrument_type Ù…Ø¹ØªØ¨Ø± (saham / retail / block / rights_issue) Ø¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
                    status_code=200,
                )
        # Ø§Ú¯Ø± Ø³ØªÙˆÙ† instrument_type Ù†Ø¨Ø§Ø´Ø¯ØŒ Ù…Ø«Ù„ Ù‚Ø¨Ù„ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… Ùˆ 500 Ù†Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…

    # --- Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… ---
    need = {"total_buy", "total_sell", "minute", group_col}
    miss = need - set(df.columns)
    if miss:
        raise HTTPException(status_code=500, detail=f"Missing columns: {', '.join(miss)}")

    # --- Ù…Ø­Ø§Ø³Ø¨Ù‡ net_value ---
    df["net_value"] = (df["total_buy"].fillna(0) - df["total_sell"].fillna(0)).astype(float)
    df["minute"] = pd.to_datetime(df["minute"], errors="coerce")
    df = df.dropna(subset=["minute"]).sort_values("minute")

    minutes = sorted(df["minute"].unique())
    if not minutes:
        return create_response(
            data=[],
            message="Ù‡ÛŒÚ† Ø²Ù…Ø§Ù† Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡â€ŒÛŒ 09:00 ØªØ§ 13:00 Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
            status_code=200,
        )

    groups = df[group_col].astype(str).unique().tolist()

    # Ø¬Ù…Ø¹ net_value Ø¯Ø± Ù‡Ø± Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ Ù‡Ø± Ú¯Ø±ÙˆÙ‡
    tmp = df.groupby(["minute", group_col], as_index=False)["net_value"].sum()

    # --- Ø³Ø§Ø®Øª bump chart: rankÙ‡Ø§ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù† ---
    bump = defaultdict(list)
    for m in minutes:
        slice_m = tmp[tmp["minute"] == pd.Timestamp(m)]
        if slice_m.empty:
            for g in groups:
                bump[g].append(None)
            continue

        slice_m = slice_m.sort_values("net_value", ascending=False).reset_index(drop=True)
        slice_m["rank"] = slice_m.index + 1
        rank_map = dict(zip(slice_m[group_col].astype(str), slice_m["rank"]))

        for g in groups:
            bump[g].append(rank_map.get(g))

    ranking_df = pd.DataFrame(bump, index=minutes).ffill().bfill()

    payload = {
        "minutes": [pd.Timestamp(m).strftime("%H:%M") for m in minutes],
        "series": [{"name": g, "ranks": ranking_df[g].tolist()} for g in groups],
    }

    return create_response(
        data=payload,
        message="âœ… Bump chart Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ (09:00 ØªØ§ 13:00)",
        status_code=200,
    )
