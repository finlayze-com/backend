# backend/api/orderbook.py
# -*- coding: utf-8 -*-

from enum import Enum
from collections import defaultdict
from fastapi import APIRouter, Query, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
import pandas as pd
from datetime import datetime, time
import re

from backend.api.metadata import get_db
from backend.users.dependencies import require_permissions
from backend.utils.sql_loader import load_sql
from backend.utils.response import create_response

router = APIRouter(prefix="/orderbook", tags=["ğŸ“Š Orderbook"])


class Mode(str, Enum):
    sector = "sector"
    intra = "intra-sector"


def normalize_persian(t: str | None):
    """Normalize Persian/Arabic characters (ÙŠ/ÛŒØŒ Ùƒ/Ú©ØŒ Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡ØŒ Ú©Ø´ÛŒØ¯Ù‡)."""
    if t is None:
        return None
    if not isinstance(t, str):
        t = str(t)
    t = t.strip().lower()
    return (
        t.replace("ÙŠ", "ÛŒ")
         .replace("Ùƒ", "Ú©")
         .replace("\u200c", "")
         .replace("Ù€", "")
    )


@router.get("/bumpchart", summary="Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø®Ø§Ù„Øµ Ø³ÙØ§Ø±Ø´â€ŒÙ‡Ø§ (Bump Chart)")
async def get_orderbook_bumpchart_data(
    mode: Mode = Query(Mode.sector, description="sector ÛŒØ§ intra-sector"),
    sector: str | None = Query(None, description="Ù†Ø§Ù… ØµÙ†Ø¹Øª Ø¯Ø± Ø­Ø§Ù„Øª intra-sector"),
    db: AsyncSession = Depends(get_db),
    _=Depends(require_permissions("Report.OrderBook.BumpChart", "ALL")),
):
    # 1) Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
    if mode == Mode.intra and not sector:
        raise HTTPException(status_code=400, detail="sector is required in intra-sector mode")

    # Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² ÙÙ‚Ø· ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ± Ù†Ø±Ù… Ø±ÙˆÛŒ df
    norm_sector = normalize_persian(sector) if sector else None

    # 2) Ø§Ù†ØªØ®Ø§Ø¨ SQL Ø¨Ø± Ø§Ø³Ø§Ø³ mode
    base_sql = (
        load_sql("orderbook_sector_timeseries")
        if mode == Mode.sector
        else load_sql("orderbook_intrasector_timeseries")
    )
    base_sql_clean = re.sub(r";\s*$", "", base_sql.strip())

    group_col = "sector" if mode == Mode.sector else "Symbol"

    # 3) Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ²ÛŒ Ú©Ù‡ orderbook_snapshot Ø¯ÛŒØªØ§ Ø¯Ø§Ø±Ø¯
    last_day_res = await db.execute(
        text('SELECT MAX("Timestamp"::date) AS d FROM orderbook_snapshot')
    )
    last_day = last_day_res.scalar()

    if not last_day:
        return create_response(
            data=[],
            message="âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ orderbook_snapshot ÛŒØ§ÙØª Ù†Ø´Ø¯.",
            status_code=200,
        )

    # Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‡Ù…Ø§Ù† 09:00 ØªØ§ 13:00 ÙˆÙ„ÛŒ Ø±ÙˆÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    start_naive = datetime.combine(last_day, time(9, 0))
    end_naive = datetime.combine(last_day, time(13, 0))

    # 4) Ù¾ÛŒÚ†ÛŒØ¯Ù† SQL Ø¯Ø± CTE Ùˆ ÙÛŒÙ„ØªØ± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ
    sql = f"""
    WITH src AS (
        {base_sql_clean}
    )
    SELECT *
    FROM src
    WHERE minute >= :start AND minute < :end
    """

    params = {"start": start_naive, "end": end_naive}
    if mode == Mode.intra:
        # sector Ø®Ø§Ù… Ø±Ø§ Ø¨Ù‡ SQL Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…Ø› Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² Ø¯Ø± SQL ÛŒØ§ Ø±ÙˆÛŒ df Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯
        params["sector"] = sector

    # 5) Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ
    res = await db.execute(text(sql), params)
    rows = res.mappings().all()
    if not rows:
        return create_response(
            data=[],
            message="âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ (09:00 ØªØ§ 13:00) ÛŒØ§ÙØª Ù†Ø´Ø¯.",
            status_code=200,
        )

    df = pd.DataFrame(rows)

    # 6) Ø¯Ø± Ø­Ø§Ù„Øª intrasector: ÙÛŒÙ„ØªØ± instrument_type Ø±ÙˆÛŒ saham/rtail/Block/right_issue
    if mode == Mode.intra:
        allowed_types = {"saham", "retail", "block","rights_issue"}
        if "instrument_type" in df.columns:
            df["instrument_type"] = df["instrument_type"].astype(str).str.lower()
            df = df[df["instrument_type"].isin(allowed_types)]
            if df.empty:
                return create_response(
                    data=[],
                    message="Ù‡ÛŒÚ† Ù†Ù…Ø§Ø¯ÛŒ Ø¨Ø§ instrument_type Ù…Ø¹ØªØ¨Ø± (saham/Block/ratail) Ø¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
                    status_code=200,
                )
        else:
            # Ø§Ú¯Ø± Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… Ø±Ø§ Ø¯ÛŒØ¯ÛŒ ÛŒØ¹Ù†ÛŒ Ø¨Ø§ÛŒØ¯ Ø¯Ø± SQL Ø³ØªÙˆÙ† instrument_type Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒ
            return create_response(
                data=[],
                message="Ø³ØªÙˆÙ† instrument_type Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ orderbook_intrasector_timeseries ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.",
                status_code=200,
            )

    # 7) Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… Ø³Ú©ØªÙˆØ± Ø±ÙˆÛŒ df (Ø¨Ø±Ø§ÛŒ Ù…Ø´Ú©Ù„ ÙŠ/ÛŒ Ùˆ ... Ø¯Ø± Ø­Ø§Ù„Øª intra)
    if mode == Mode.intra and norm_sector:
        if "sector" in df.columns:
            df["sector_norm"] = df["sector"].astype(str).apply(normalize_persian)
            df = df[df["sector_norm"] == norm_sector]
            if df.empty:
                return create_response(
                    data=[],
                    message=f"Ø¨Ø¹Ø¯ Ø§Ø² Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Â«{sector}Â» Ø¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
                    status_code=200,
                )

    # 8) Ú†Ú© Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ
    need = {"total_buy", "total_sell", "minute", group_col}
    cols = set(df.columns)
    miss = need - cols
    if miss:
        raise HTTPException(
            status_code=500,
            detail=f"Missing columns: {', '.join(miss)} | columns: {list(cols)}",
        )

    # 9) Ù…Ø­Ø§Ø³Ø¨Ù‡ net_value Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
    df["net_value"] = (df["total_buy"].fillna(0) - df["total_sell"].fillna(0)).astype(float)
    df["minute"] = pd.to_datetime(df["minute"], errors="coerce")
    df = df.dropna(subset=["minute"]).sort_values("minute")

    minutes = sorted(df["minute"].unique())
    if not minutes:
        return create_response(
            data=[],
            message="Ù‡ÛŒÚ† Ø²Ù…Ø§Ù† Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.",
            status_code=200,
        )

    groups = df[group_col].astype(str).unique().tolist()

    # 10) Ø¬Ù…Ø¹â€ŒØ²Ø¯Ù† Ø¯Ø± Ù‡Ø± Ø¯Ù‚ÛŒÙ‚Ù‡ Ùˆ Ù‡Ø± Ú¯Ø±ÙˆÙ‡
    tmp = df.groupby(["minute", group_col], as_index=False)["net_value"].sum()

    # 11) Ø³Ø§Ø®Øª Bump Chart (Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ù‡Ø± Ø¯Ù‚ÛŒÙ‚Ù‡)
    bump = defaultdict(list)
    for m in minutes:
        slice_m = tmp[tmp["minute"] == pd.Timestamp(m)]
        if slice_m.empty:
            for g in groups:
                bump[g].append(None)
            continue

        slice_m = slice_m.sort_values("net_value", ascending=False).reset_index(drop=True)
        slice_m["rank"] = slice_m.index + 1
        rank_map = dict(zip(slice_m[group_col].astype(str), slice_m["rank"]))

        for g in groups:
            bump[g].append(rank_map.get(g))

    ranking_df = pd.DataFrame(bump, index=minutes).ffill().bfill()

    # 12) Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ù†Øª
    payload = {
        "minutes": [pd.Timestamp(m).strftime("%H:%M") for m in minutes],
        "series": [
            {"name": g, "ranks": ranking_df[g].tolist()}
            for g in groups
        ],
        "meta": {
            "last_trading_date": last_day.strftime("%Y-%m-%d"),
            "mode": mode,
            "sector": sector,
        },
    }

    return create_response(
        data=payload,
        message=f"âœ… Bump chart Ø¨Ø±Ø§ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ (ØªØ§Ø±ÛŒØ®: {last_day.strftime('%Y-%m-%d')}, Ø³Ø§Ø¹Øª 09:00 ØªØ§ 13:00)",
        status_code=200,
    )
