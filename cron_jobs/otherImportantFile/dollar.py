# #Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ÙˆÙ‚ØªÛŒ Ú©Ù‡ Ú©Ù„ Ø¯ÛŒØªØ§ Ø¨ÛŒØ³ ØªØ§Ø±ÛŒØ®ÛŒ Ø±Ùˆ Ù…ÛŒØ®ÙˆØ§ÛŒÙ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒÙ… ØªÙˆ Ø¯ÛŒØªØ§ Ø¨ÛŒØ³ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒÙ…
# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from webdriver_manager.chrome import ChromeDriverManager
# from selenium.webdriver.chrome.options import Options
# from bs4 import BeautifulSoup
# import pandas as pd
# import psycopg2
# import time
#
# # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø±ÙˆØ±Ú¯Ø± (headless)
# options = Options()
# options.add_argument("--headless")
# options.add_argument("--no-sandbox")
# options.add_argument("--disable-dev-shm-usage")
#
# # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±
# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
#
# # Ø¢Ø¯Ø±Ø³ Ø³Ø§ÛŒØª
# url = 'https://www.tgju.org/profile/price_dollar_rl/history'
# driver.get(url)
# time.sleep(5)
#
# # Ù¾Ø§Ø±Ø³ HTML Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ø§ÙˆØ§Ø§Ø³Ú©Ø±ÛŒÙ¾Øª
# soup = BeautifulSoup(driver.page_source, 'html.parser')
# driver.quit()
#
# # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯ÙˆÙ„
# table = soup.find('table', {'id': 'DataTables_Table_0'})
# tbody = table.find('tbody')
#
# # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# rows = []
# for tr in tbody.find_all('tr'):
#     tds = tr.find_all('td')
#     if len(tds) == 8:
#         open_, low, high, close, *_ , date_gregorian, _ = [td.text.strip().replace(',', '') for td in tds]
#         rows.append((date_gregorian, open_, high, low, close))
#
# # Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…
# df = pd.DataFrame(rows, columns=['date_miladi', 'open', 'high', 'low', 'close'])
# df['date_miladi'] = pd.to_datetime(df['date_miladi'], format='%Y/%m/%d')
#
# # Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
# conn = psycopg2.connect(
#     host='localhost',
#     dbname='postgres1',
#     user='postgres',
#     password='Afiroozi12'
# )
# cur = conn.cursor()
#
# # Ú¯Ø±ÙØªÙ† ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø² Ù‚Ø¨Ù„ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‡Ø³ØªÙ†Ø¯
# cur.execute("SELECT date_miladi FROM dollar_data;")
# existing_dates = set(row[0] for row in cur.fetchall())
#
# # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ ØªØ§Ø±ÛŒØ®Ø´Ø§Ù† Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª
# df_new = df[~df['date_miladi'].isin(existing_dates)]
#
# # Ø¯Ø±Ø¬ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÙÙ‚Ø· Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
# insert_query = """
#     INSERT INTO dollar_data (date_miladi, open, high, low, close)
#     VALUES (%s, %s, %s, %s, %s);
# """
# records = list(df_new.itertuples(index=False, name=None))
# if records:
#     cur.executemany(insert_query, records)
#     conn.commit()
#
# print(f"âœ… {len(records)} Ø±Ø¯ÛŒÙ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ dollar_data Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")
#
# cur.close()
# conn.close()


# -*- coding: utf-8 -*-
"""
Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù†Ø±Ø® Ø¯Ù„Ø§Ø± Ø§Ø² tgju Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Postgres.

- Ø¨Ø¯ÙˆÙ† webdriver-manager (Ø­Ù„ Ù…Ø´Ú©Ù„ CDN)
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chromedriver Ø³ÛŒØ³ØªÙ…
- Ø®ÙˆØ§Ù†Ø¯Ù† DB_URL Ø§Ø² .env (fallback Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø«Ø§Ø¨Øª)
- Ø¢Ù¾Ø³Ø±Øª Ø±ÙˆÛŒ date_miladi

Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:
    source .venv/bin/activate
    python -m cron_jobs.otherImportantFile.dollar
"""

import os
import sys
import time
import shutil
import traceback
from pathlib import Path
from datetime import datetime

from dotenv import load_dotenv
import pandas as pd
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service

import psycopg2
from psycopg2.extras import execute_batch


# ---------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ ----------
REPO_ROOT = Path(__file__).resolve().parents[2]  # /root/backend
ENV_PATH = REPO_ROOT / ".env"

URL = "https://www.tgju.org/profile/price_dollar_rl/history"

HEADLESS = True
PAGELOAD_WAIT = 6  # seconds

# ---------- Ú©Ù…Ú©â€ŒØªØ§Ø¨Ø¹â€ŒÙ‡Ø§ ----------
def log(msg: str):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}", flush=True)

def get_db_url():
    # ØªØ±ØªÛŒØ¨ Ø§ÙˆÙ„ÙˆÛŒØª: DB_URL -> DB_URL_SYNC -> DATABASE_URL
    db_url = os.getenv("DB_URL") or os.getenv("DB_URL_SYNC") or os.getenv("DATABASE_URL")
    if db_url:
        return db_url

    # fallback Ø¨Ù‡ Ø§ØªØµØ§Ù„ Ø¯Ø³ØªÛŒ (Ø§Ú¯Ø± env Ù†Ø¨ÙˆØ¯)
    host = os.getenv("DB_HOST", "localhost")
    dbname = os.getenv("DB_NAME", "postgres1")
    user = os.getenv("DB_USER", "postgres")
    password = os.getenv("DB_PASSWORD", "Afiroozi12")
    port = os.getenv("DB_PORT", "5432")
    return f"postgresql://{user}:{password}@{host}:{port}/{dbname}"

def connect_db(db_url: str):
    # psycopg2 Ø¨Ø§ DSN Ù‡Ù… Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    conn = psycopg2.connect(db_url)
    conn.autocommit = False
    return conn

def get_chromedriver_path() -> str:
    # Ø§ÙˆÙ„ Ø¨Ø§ which
    p = shutil.which("chromedriver")
    if p:
        return p
    # fallback Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø±Ø§ÛŒØ¬
    candidates = [
        "/usr/bin/chromedriver",
        "/usr/lib/chromium-browser/chromedriver",
        "/usr/lib/chromium/chromedriver",
        "/usr/local/bin/chromedriver",
    ]
    for c in candidates:
        if os.path.exists(c):
            return c
    raise RuntimeError(
        "chromedriver ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ù†ØµØ¨ Ú©Ù†:\n"
        "  sudo apt-get install -y chromium-driver\n"
        "Ùˆ Ø³Ù¾Ø³ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†."
    )

def new_driver():
    options = Options()
    if HEADLESS:
        # Ø­Ø§Ù„Øª Ø¬Ø¯ÛŒØ¯ headless Ø¨Ø±Ø§ÛŒ Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1440,900")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-features=VizDisplayCompositor")
    options.add_argument("--user-agent=Mozilla/5.0 (X11; Linux x86_64) "
                         "AppleWebKit/537.36 (KHTML, like Gecko) "
                         "Chrome/118.0.0.0 Safari/537.36")

    # Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¨ÙˆØ¯ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ø±ÙˆÙ…ÛŒÙˆÙ… Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù† (Ø¨Ø¹Ø¶ÛŒ Ø³Ø±ÙˆØ±Ù‡Ø§)
    # options.binary_location = "/usr/bin/chromium-browser"  # ÛŒØ§ /usr/bin/chromium

    driver_path = get_chromedriver_path()
    service = Service(executable_path=driver_path)
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def fetch_html() -> str:
    log(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡: {URL}")
    driver = new_driver()
    try:
        driver.get(URL)
        time.sleep(PAGELOAD_WAIT)
        html = driver.page_source
        return html
    finally:
        try:
            driver.quit()
        except Exception:
            pass

def parse_table(html: str) -> pd.DataFrame:
    """
    Ø¬Ø¯ÙˆÙ„ Ø¨Ø§ id=DataTables_Table_0 â†’ Ù‡Ø´Øª Ø³ØªÙˆÙ† (Ø¨Ø§Ø²ØŒÚ©Ù…ØªØ±ÛŒÙ†ØŒØ¨ÛŒØ´ØªØ±ÛŒÙ†ØŒÙ¾Ø§ÛŒØ§Ù†ÛŒØŒ...ØŒØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒØŒâ€¦)
    Ø³Ø§Ø®ØªØ§Ø± Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªÙˆØ³Ø· Ø³Ø§ÛŒØª ØªØºÛŒÛŒØ± Ú©Ù†Ø¯Ø› Ø¯Ø± ØµÙˆØ±Øª ØªØºÛŒÛŒØ±ØŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø¯Ù‡.
    """
    soup = BeautifulSoup(html, "html.parser")
    table = soup.find("table", {"id": "DataTables_Table_0"})
    if not table:
        raise ValueError("Ø¬Ø¯ÙˆÙ„ Ø¨Ø§ id=DataTables_Table_0 Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø´Ø§ÛŒØ¯ Ø³Ø§Ø®ØªØ§Ø± ØµÙØ­Ù‡ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡.")

    tbody = table.find("tbody")
    if not tbody:
        raise ValueError("tbody Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")

    rows = []
    for tr in tbody.find_all("tr"):
        tds = [td.get_text(strip=True) for td in tr.find_all("td")]
        # Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 8 Ø³ØªÙˆÙ†Ù‡ Ø§Ø³ØªØ› Ø§Ú¯Ø± ØªØºÛŒÛŒØ± Ú©Ø±Ø¯ØŒ Ù„Ø§Ú¯ Ø¨Ú¯ÛŒØ±
        if len(tds) < 7:
            continue

        # Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ØªØ±ØªÛŒØ¨: Ø¨Ø§Ø²ØŒ Ú©Ù…ØªØ±ÛŒÙ†ØŒ Ø¨ÛŒØ´ØªØ±ÛŒÙ†ØŒ Ù¾Ø§ÛŒØ§Ù†ÛŒØŒ ... ØŒ ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒØŒ ...
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ø¹Ø¯Ø§Ø¯
        try:
            # Ø­Ø°Ù ÙˆÛŒØ±Ú¯ÙˆÙ„
            cleaned = [c.replace(",", "") for c in tds]
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ØªØ§Ø±ÛŒØ® Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªÙ‡Ø§ÛŒÛŒ
            # Ø¯Ø± Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø§Ø² Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ Ø³ØªÙˆÙ† 6 ØªØ§Ø±ÛŒØ® Ø§Ø³Øª (Ø§ÛŒÙ†Ø¯Ú©Ø³ 6 ÛŒØ§ -2)
            # Ø§Ù…Ù†â€ŒØªØ±: Ø§Ø² Ø±Ø§Ø³Øª Ø¨Ù‡ Ú†Ù¾ Ø§ÙˆÙ„ÛŒÙ† Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ø´Ø¨ÛŒÙ‡ ØªØ§Ø±ÛŒØ® Ù‡Ø³Øª Ø±Ø§ Ø¨Ø±Ø¯Ø§Ø±
            date_idx = None
            for i in range(len(cleaned)-1, -1, -1):
                token = cleaned[i]
                if "/" in token and len(token.split("/")) == 3:
                    date_idx = i
                    break
            if date_idx is None:
                # fallback: ÙØ±Ø¶ 6
                date_idx = 6

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ
            date_gregorian = cleaned[date_idx]

            # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù‚ÛŒÙ…Øª Ø±Ø§ Ø§Ø² Ø§Ø¨ØªØ¯Ø§ÛŒ Ø±Ø¯ÛŒÙ Ø¨Ø±Ø¯Ø§Ø± (ÙØ±Ø¶: 0..3)
            open_, low, high, close = cleaned[0:4]

            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ float
            def to_float(x):
                try:
                    return float(x)
                except:
                    return None

            rows.append(
                (
                    date_gregorian.strip(),
                    to_float(open_),
                    to_float(high),
                    to_float(low),
                    to_float(close),
                )
            )
        except Exception as e:
            log(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ ÛŒÚ© Ø±Ø¯ÛŒÙ: {e}")

    if not rows:
        raise ValueError("Ù‡ÛŒÚ† Ø³Ø·Ø±ÛŒ Ø§Ø² Ø¬Ø¯ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯. Ø´Ø§ÛŒØ¯ ØµÙØ­Ù‡ Ú©Ø§Ù…Ù„ Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ ÛŒØ§ DOM ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡.")

    df = pd.DataFrame(rows, columns=["date_miladi", "open", "high", "low", "close"])

    # ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ Ø¨Ø§ ÙØ±Ù…Øª  YYYY/MM/DD
    def parse_date(s):
        # Ø¨Ø±Ø®ÛŒ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª dash Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ù†Ø¯
        s = (s or "").strip()
        for fmt in ("%Y/%m/%d", "%Y-%m-%d"):
            try:
                return datetime.strptime(s, fmt).date()
            except:
                pass
        return None

    df["date_miladi"] = df["date_miladi"].map(parse_date)
    df = df.dropna(subset=["date_miladi"]).copy()
    return df

def ensure_table(conn):
    """
    Ø§Ú¯Ø± Ø¬Ø¯ÙˆÙ„ dollar_data ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ø³Ø§Ø² (Ø³ØªÙˆÙ† date_miladi ÛŒÚ©ØªØ§ Ø¨Ø§Ø´Ø¯ Ø¨Ø±Ø§ÛŒ upsert).
    Ø§Ú¯Ø± Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø±ÛŒØŒ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨ÛŒâ€ŒØ®Ø·Ø± Ø§Ø³Øª.
    """
    ddl = """
    CREATE TABLE IF NOT EXISTS public.dollar_data (
        date_miladi date PRIMARY KEY,
        open numeric,
        high numeric,
        low  numeric,
        close numeric
    );
    """
    with conn.cursor() as cur:
        cur.execute(ddl)
    conn.commit()

def upsert_dollar_data(conn, df: pd.DataFrame):
    """
    Ø¢Ù¾Ø³Ø±Øª Ø¨Ø± Ø§Ø³Ø§Ø³ date_miladi.
    Ø§Ú¯Ø± constraint ÛŒÚ©ØªØ§ Ù†Ø¯Ø§Ø±ÛŒØŒ Ø­ØªÙ…Ø§Ù‹ PRIMARY KEY ÛŒØ§ UNIQUE Ø±ÙˆÛŒ date_miladi Ø¨Ú¯Ø°Ø§Ø±.
    """
    if df.empty:
        log("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø¬ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        return 0

    sql = """
    INSERT INTO public.dollar_data (date_miladi, open, high, low, close)
    VALUES (%s, %s, %s, %s, %s)
    ON CONFLICT (date_miladi)
    DO UPDATE SET
        open = EXCLUDED.open,
        high = EXCLUDED.high,
        low  = EXCLUDED.low,
        close= EXCLUDED.close;
    """
    records = [(r.date_miladi, r.open, r.high, r.low, r.close) for r in df.itertuples(index=False)]
    with conn.cursor() as cur:
        execute_batch(cur, sql, records, page_size=1000)
    conn.commit()
    return len(records)

def main():
    try:
        if ENV_PATH.exists():
            load_dotenv(ENV_PATH)
            log(f".env loaded from {ENV_PATH}")
        else:
            log("âš ï¸ ÙØ§ÛŒÙ„ .env Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø§Ø² Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ ÙØ¹Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù….")

        db_url = get_db_url()
        log(f"DB_URL: {db_url}")

        html = fetch_html()
        log("HTML Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")

        df = parse_table(html)
        log(f"ğŸ§® Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡: {len(df)}")

        conn = connect_db(db_url)
        try:
            ensure_table(conn)

            # Ø§Ú¯Ø± ÙÙ‚Ø· Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒ Ø³Ø·Ø±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¯Ø±Ø¬ Ú©Ù†ÛŒ (Ùˆ Ù†Ù‡ Ø¢Ù¾Ø¯ÛŒØª):
            #   - Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒ Ø§Ø¨ØªØ¯Ø§ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†ÛŒ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ù†ÛŒ.
            #   - ÙˆÙ„ÛŒ Ù…Ø§ Ø¢Ù¾Ø³Ø±Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ù…Ø·Ù…Ø¦Ù† Ø¨Ø§Ø´ÛŒÙ… Ù…Ù‚Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ² Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
            inserted = upsert_dollar_data(conn, df)
            log(f"âœ… {inserted} Ø±Ø¯ÛŒÙ Ø¯Ø±Ø¬/Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯ Ø¯Ø± dollar_data.")
        finally:
            conn.close()

        log("ğŸ‰ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    except Exception as e:
        log("âŒ Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯:")
        print(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()
