import os, time, requests, csv, tempfile
from dotenv import load_dotenv
from psycopg2.extras import execute_batch
import psycopg2

# .env
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '..', '.env')
load_dotenv(dotenv_path)
DB_URL = os.getenv("DB_URL_SYNC")

# Ù…Ø³ÛŒØ±Ù‡Ø§
BASE_DIR = os.path.join(os.path.dirname(__file__), '..', '..')
DOCUMENT_DIR = os.path.join(BASE_DIR, 'backend', 'Document')

# ÙÙ‚Ø· Ù†Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§Ø› Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ Ø±Ø§ Ø¨Ø¹Ø¯Ø§Ù‹ Ø¨Ø§ DOCUMENT_DIR Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…
FILES = {
    'saham.txt':   'saham',      # Ø³Ù‡Ø§Ù…
    'saham -R.txt': 'rights_issue',     #Ø­Ù‚ ØªÙ‚Ø¯Ù…
    'saham -2.txt': 'retail',           #Ø®Ø±Ø¯Ù‡ ÙØ±ÙˆØ´ÛŒ
    'saham -4.txt': 'Block',            #Ø¨Ù„ÙˆÚ©ÛŒ
    'fund_stock.txt': 'fund_stock',              # ØµÙ†Ø¯ÙˆÙ‚ Ø³Ù‡Ø§Ù…ÛŒ
    'fund_segment.txt': 'fund_segment',  # ØµÙ†Ø¯ÙˆÙ‚ Ø¨Ø®Ø´ÛŒ
    'fund_balanced.txt': 'fund_balanced',  # ØµÙ†Ø¯ÙˆÙ‚ Ù…Ø®ØªÙ„Ø·
    'fund_fixincome.txt': 'fund_fixincome',  # ØµÙ†Ø¯ÙˆÙ‚ Ø¯Ø±Ø§Ù…Ø¯ Ø«Ø§Ø¨Øª
    'fund_gold.txt': 'fund_gold',  # ØµÙ†Ø¯ÙˆÙ‚ Ø·Ù„Ø§
    'fund_index_stock.txt': 'fund_index_stock',  # ØµÙ†Ø¯ÙˆÙ‚ Ø´Ø§Ø®ØµÛŒ
    'fund_leverage.txt': 'fund_leverage',  # ØµÙ†Ø¯ÙˆÙ‚ Ø´Ø§Ø®ØµÛŒ
    'fund_zafran.txt': 'fund_zafran',  # ØµÙ†Ø¯ÙˆÙ‚ Ø´Ø§Ø®ØµÛŒ
    'fund_other.txt': 'fund_other',  # ØµÙ†Ø¯ÙˆÙ‚ Ø´Ø§Ø®ØµÛŒ
    'option.txt':  'option',            # Ø§Ø®ØªÛŒØ§Ø±
    'kala.txt':    'commodity',         # Ú©Ø§Ù„Ø§ÛŒÛŒ
    'tamin.txt':   'bond',              # ØªØ§Ù…ÛŒÙ† Ù…Ø§Ù„ÛŒ
}

def read_ids_with_type():
    rows = []
    for filename, inst_type in FILES.items():
        path = os.path.join(DOCUMENT_DIR, filename)
        if not os.path.exists(path):
            print(f"âš ï¸ ÙØ§ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯: {path}")
            continue
        with open(path, 'r', encoding='utf-8') as f:
            ids = [line.strip() for line in f if line.strip()]
        # Ù‡Ø± id Ø±Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ù†ÙˆØ¹ Ø§Ø¨Ø²Ø§Ø± Ùˆ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ù…Ù†Ø¨Ø¹ Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒÙ…
        rows.extend([(ins, inst_type, filename) for ins in ids])
    return rows

def fetch_info(inscode):
    url = f"https://cdn.tsetmc.com/api/Instrument/GetInstrumentInfo/{inscode}"
    r = requests.get(url, timeout=20)
    r.raise_for_status()
    info = (r.json() or {}).get("instrumentInfo", {}) or {}
    return {
        "insCode": info.get("insCode"),
        "name": info.get("lVal30"),
        "name_en": info.get("lVal18"),
        "sector": (info.get("sector") or {}).get("lSecVal"),
        "sector_code": (info.get("sector") or {}).get("cSecVal"),
        "subsector": info.get("faraDesc"),
        "market": info.get("flowTitle"),
        "panel": info.get("cgrValCotTitle"),
        "stock_ticker": info.get("lVal18AFC"),
        "share_number": info.get("zTitad"),
        "base_vol": info.get("baseVol"),
        "instrumentID": info.get("instrumentID"),
    }

def upsert_symboldetail(rows):
    # Ù¾ÙˆØ´Ø´ Ú©Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ + source_file
    cols = [
        "insCode","name","name_en","sector","sector_code","subsector","market","panel",
        "stock_ticker","share_number","base_vol","instrumentID","instrument_type","source_file"
    ]
    # Ù‡Ù…Ù‡â€ŒÛŒ Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø§Ø¨Ù„â€ŒÚ©ÙˆØªÛŒØ´Ù† Ú©Ù† ØªØ§ case Ø­ÙØ¸ Ø´ÙˆØ¯
    cols_sql = ",".join([f'"{c}"' for c in cols])

    insert_sql = f"""
        INSERT INTO symboldetail
        ({cols_sql})
        VALUES ({",".join(["%s"]*len(cols))})
        ON CONFLICT ("insCode") DO UPDATE SET
            "name"          = EXCLUDED."name",
            "name_en"       = EXCLUDED."name_en",
            "sector"        = EXCLUDED."sector",
            "sector_code"   = EXCLUDED."sector_code",
            "subsector"     = EXCLUDED."subsector",
            "market"        = EXCLUDED."market",
            "panel"         = EXCLUDED."panel",
            "stock_ticker"  = EXCLUDED."stock_ticker",
            "share_number"  = EXCLUDED."share_number",
            "base_vol"      = EXCLUDED."base_vol",
            "instrumentID"  = EXCLUDED."instrumentID",
            "instrument_type" = EXCLUDED."instrument_type",
            "source_file"   = EXCLUDED."source_file";
    """

    values = [[r.get(c) for c in cols] for r in rows]

    with psycopg2.connect(DB_URL) as conn:
        with conn.cursor() as cur:
            execute_batch(cur, insert_sql, values, page_size=500)
        conn.commit()

def main():
    id_type_pairs = read_ids_with_type()
    out, failed = [], []
    total = len(id_type_pairs)

    for i, (ins, inst_type, filename) in enumerate(id_type_pairs, 1):
        try:
            info = fetch_info(ins)
            if not info.get("insCode"):
                raise ValueError("empty insCode from API")
            info["instrument_type"] = inst_type
            info["source_file"] = filename
            out.append(info)
            # ğŸ‘‡ Ù¾Ø±ÛŒÙ†Øª Ù¾ÛŒØ´Ø±ÙØª
            print(f"[{i}/{total}] âœ… Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {ins} ({inst_type})")

        except Exception as e:
            failed.append((ins, inst_type, str(e)))
            print(f"âŒ {ins} ({inst_type}) : {e}")
        finally:
            time.sleep(0)

        if out and len(out) % 100 == 0:
            print(f"ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ 100 Ø±Ú©ÙˆØ±Ø¯ ØªØ§ Ø§Ù„Ø§Ù† ...")
            upsert_symboldetail(out)
            out.clear()

    if out:
        print(f"ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ {len(out)} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ ...")
        upsert_symboldetail(out)

    print(f"âœ… Done. saved={len(id_type_pairs)-len(failed)} failed={len(failed)}")
    if failed:
        tmp = tempfile.gettempdir()
        fail_path = os.path.join(tmp, "symboldetail_failed.csv")
        with open(fail_path, "w", newline="", encoding="utf-8") as f:
            w = csv.writer(f); w.writerow(["insCode","instrument_type","error"]); w.writerows(failed)
        print(f"âš ï¸ failed list: {fail_path}")

if __name__ == "__main__":
    main()